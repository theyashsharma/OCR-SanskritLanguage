{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b49fee2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yasha\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\yasha\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\yasha\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "358b52d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm  \n",
    "import tensorflow.keras\n",
    "import math\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02e4d9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"E:\\Projects\\OCR-Sanskrit\\DevanagariHandwrittenCharacterDataset\\Train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cbb99e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"E:\\Projects\\OCR-Sanskrit\\DevanagariHandwrittenCharacterDataset\\Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6efa70bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os.path\n",
    "\n",
    "filename = os.path.join('E:/Projects/OCR-Sanskrit/DevanagariHandwrittenCharacterDataset/Train/character_10_yna/10542.png')\n",
    "img = Image.open(filename)\n",
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "023c3d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,    \n",
    "    data_format='channels_first',\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "860c78e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 62560 images belonging to 46 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(32, 32),\n",
    "    color_mode = \"grayscale\",\n",
    "    batch_size=20,\n",
    "    shuffle = True,\n",
    "    classes = ['character_1_ka','character_2_kha','character_3_ga','character_4_gha','character_5_kna','character_6_cha',\n",
    "               'character_7_chha','character_8_ja','character_9_jha','character_10_yna','character_11_taamatar','character_12_thaa',\n",
    "               'character_13_daa', 'character_14_dhaa', 'character_15_adna', 'character_16_tabala', 'character_17_tha',\n",
    "               'character_18_da', 'character_19_dha', 'character_20_na', 'character_21_pa', 'character_22_pha','character_23_ba',\n",
    "               'character_24_bha','character_25_ma', 'character_26_yaw', 'character_27_ra', 'character_28_la', 'character_29_waw',\n",
    "               'character_30_motosaw', 'character_31_petchiryakha', 'character_32_patalosaw', 'character_33_ha', 'character_34_chhya', 'character_35_tra', \n",
    "               'character_36_gya','digit_0','digit_1','digit_2','digit_3','digit_4','digit_5','digit_6','digit_7','digit_8','digit_9'],\n",
    "    class_mode=\"sparse\",\n",
    "    subset='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c14d8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.preprocessing.image.DirectoryIterator at 0x23e9cd9ad60>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "975e87fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15640 images belonging to 46 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, # same directory as training data\n",
    "    target_size=(32, 32),\n",
    "    color_mode = \"grayscale\",\n",
    "    batch_size=20,\n",
    "    shuffle = True,\n",
    "    classes = ['character_1_ka','character_2_kha','character_3_ga','character_4_gha','character_5_kna','character_6_cha',\n",
    "               'character_7_chha','character_8_ja','character_9_jha','character_10_yna','character_11_taamatar','character_12_thaa',\n",
    "               'character_13_daa', 'character_14_dhaa', 'character_15_adna', 'character_16_tabala', 'character_17_tha',\n",
    "               'character_18_da', 'character_19_dha', 'character_20_na', 'character_21_pa', 'character_22_pha','character_23_ba',\n",
    "               'character_24_bha','character_25_ma', 'character_26_yaw', 'character_27_ra', 'character_28_la', 'character_29_waw',\n",
    "               'character_30_motosaw', 'character_31_petchiryakha', 'character_32_patalosaw', 'character_33_ha', 'character_34_chhya', 'character_35_tra', \n",
    "               'character_36_gya','digit_0','digit_1','digit_2','digit_3','digit_4','digit_5','digit_6','digit_7','digit_8','digit_9'],\n",
    "    class_mode=\"sparse\",\n",
    "    subset='validation') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e17376f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255,    \n",
    "    data_format='channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4421bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13800 images belonging to 46 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(32, 32),\n",
    "    color_mode = \"grayscale\",\n",
    "    batch_size=20,\n",
    "    shuffle = True,\n",
    "    classes = ['character_1_ka','character_2_kha','character_3_ga','character_4_gha','character_5_kna','character_6_cha',\n",
    "               'character_7_chha','character_8_ja','character_9_jha','character_10_yna','character_11_taamatar','character_12_thaa',\n",
    "               'character_13_daa', 'character_14_dhaa', 'character_15_adna', 'character_16_tabala', 'character_17_tha',\n",
    "               'character_18_da', 'character_19_dha', 'character_20_na', 'character_21_pa', 'character_22_pha','character_23_ba',\n",
    "               'character_24_bha','character_25_ma', 'character_26_yaw', 'character_27_ra', 'character_28_la', 'character_29_waw',\n",
    "               'character_30_motosaw', 'character_31_petchiryakha', 'character_32_patalosaw', 'character_33_ha', 'character_34_chhya', 'character_35_tra', \n",
    "               'character_36_gya','digit_0','digit_1','digit_2','digit_3','digit_4','digit_5','digit_6','digit_7','digit_8','digit_9'],\n",
    "    class_mode=\"sparse\",\n",
    "    subset='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee5485b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2f59a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3151578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4635bb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 32, 32)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 7, 7)     1664        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 7, 7)     1664        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "merge1 (Concatenate)            (None, 128, 7, 7)    0           conv2d_10[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 128, 4, 4)    0           merge1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 128, 1, 1)    262272      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 128, 1, 1)    262272      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "merge2 (Concatenate)            (None, 256, 1, 1)    0           conv2d_12[0][0]                  \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 256, 1, 1)    0           merge2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 256, 1, 1)    590080      max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 256, 1, 1)    590080      max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 256, 1, 1)    590080      max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 256, 1, 1)    590080      max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 256, 1, 1)    590080      max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 256, 1, 1)    590080      max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "merge3 (Concatenate)            (None, 1536, 1, 1)   0           conv2d_14[0][0]                  \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 1536, 1, 1)   0           merge3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1536, 1, 1)   0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1536)         0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 46)           70702       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,139,054\n",
      "Trainable params: 4,139,054\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(1, 32, 32))\n",
    "\n",
    "fork11 = layers.Conv2D(64, 5, 5,  activation=\"relu\", padding='same')(inputs)\n",
    "fork12 = layers.Conv2D(64, 5, 5, activation=\"relu\", padding='same')(inputs)\n",
    "merge1 = layers.concatenate([fork11, fork12], axis=1, name='merge1')\n",
    "# concat_feat = concatenate([concat_feat, x], mode='concat', axis=concat_axis, name='concat_'+str(stage)+'_'+str(branch))\n",
    "maxpool1 = layers.MaxPool2D(strides=(2,2), padding='same')(merge1)\n",
    "\n",
    "fork21 = layers.Conv2D(128, 4, 4, activation=\"relu\", padding='same')(maxpool1)\n",
    "fork22 = layers.Conv2D(128, 4, 4, activation=\"relu\", padding='same')(maxpool1)\n",
    "merge2 = layers.concatenate([fork21, fork22, ], axis=1, name='merge2')\n",
    "maxpool2 = layers.MaxPool2D(strides=(2,2), padding='same')(merge2)\n",
    "\n",
    "fork31 = layers.Conv2D(256, 3, 3, activation=\"relu\", padding='same')(maxpool2)\n",
    "fork32 = layers.Conv2D(256, 3, 3, activation=\"relu\", padding='same')(maxpool2)\n",
    "fork33 = layers.Conv2D(256, 3, 3, activation=\"relu\", padding='same')(maxpool2)\n",
    "fork34 = layers.Conv2D(256, 3, 3, activation=\"relu\" , padding='same')(maxpool2)\n",
    "fork35 = layers.Conv2D(256, 3, 3, activation=\"relu\", padding='same')(maxpool2)\n",
    "fork36 = layers.Conv2D(256, 3, 3, activation=\"relu\", padding='same')(maxpool2)\n",
    "merge3 = layers.concatenate([fork31, fork32, fork33, fork34, fork35, fork36, ], axis=1, name='merge3')\n",
    "maxpool3 = layers.MaxPool2D(strides=(2,2), padding='same')(merge3)\n",
    "\n",
    "dropout = layers.Dropout(0.5)(maxpool3)\n",
    "\n",
    "flatten = layers.Flatten()(dropout)\n",
    "outputs = layers.Dense(46, activation=\"softmax\")(flatten)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b85072da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer = keras.optimizers.Adadelta(learning_rate = 1.0, rho=0.95),\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c99a45ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "100/100 [==============================] - 102s 939ms/step - loss: 3.7533 - accuracy: 0.0480 - val_loss: 3.4547 - val_accuracy: 0.1055\n",
      "Epoch 2/15\n",
      "100/100 [==============================] - 70s 705ms/step - loss: 2.9923 - accuracy: 0.1745 - val_loss: 2.4394 - val_accuracy: 0.2980\n",
      "Epoch 3/15\n",
      "100/100 [==============================] - 67s 670ms/step - loss: 2.2424 - accuracy: 0.3540 - val_loss: 2.1281 - val_accuracy: 0.3700\n",
      "Epoch 4/15\n",
      "100/100 [==============================] - 85s 851ms/step - loss: 1.7675 - accuracy: 0.4655 - val_loss: 1.7355 - val_accuracy: 0.4705\n",
      "Epoch 5/15\n",
      "100/100 [==============================] - 101s 1s/step - loss: 1.3872 - accuracy: 0.5655 - val_loss: 1.6084 - val_accuracy: 0.5120\n",
      "Epoch 6/15\n",
      "100/100 [==============================] - 93s 937ms/step - loss: 1.2220 - accuracy: 0.6175 - val_loss: 1.6475 - val_accuracy: 0.5065\n",
      "Epoch 7/15\n",
      "100/100 [==============================] - 92s 929ms/step - loss: 1.1082 - accuracy: 0.6545 - val_loss: 1.2577 - val_accuracy: 0.6260\n",
      "Epoch 8/15\n",
      "100/100 [==============================] - 109s 1s/step - loss: 0.9453 - accuracy: 0.7065 - val_loss: 1.1572 - val_accuracy: 0.6505\n",
      "Epoch 9/15\n",
      "100/100 [==============================] - 88s 880ms/step - loss: 0.8297 - accuracy: 0.7400 - val_loss: 1.1160 - val_accuracy: 0.6540\n",
      "Epoch 10/15\n",
      "100/100 [==============================] - 82s 826ms/step - loss: 0.7535 - accuracy: 0.7645 - val_loss: 1.3312 - val_accuracy: 0.6055\n",
      "Epoch 11/15\n",
      "100/100 [==============================] - 81s 809ms/step - loss: 0.7654 - accuracy: 0.7525 - val_loss: 1.0943 - val_accuracy: 0.6665\n",
      "Epoch 12/15\n",
      "100/100 [==============================] - 50s 499ms/step - loss: 0.7181 - accuracy: 0.7785 - val_loss: 1.0808 - val_accuracy: 0.6685\n",
      "Epoch 13/15\n",
      "100/100 [==============================] - 72s 710ms/step - loss: 0.6834 - accuracy: 0.7900 - val_loss: 1.0985 - val_accuracy: 0.6655\n",
      "Epoch 14/15\n",
      "100/100 [==============================] - 61s 607ms/step - loss: 0.5912 - accuracy: 0.8215 - val_loss: 1.0720 - val_accuracy: 0.6710\n",
      "Epoch 15/15\n",
      "100/100 [==============================] - 65s 651ms/step - loss: 0.5886 - accuracy: 0.8050 - val_loss: 1.0779 - val_accuracy: 0.6720\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    steps_per_epoch=100,\n",
    "                    validation_steps=100,\n",
    "                    epochs = 15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c5f0e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 293s 425ms/step - loss: 0.6412 - accuracy: 0.8065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6412396430969238, 0.8065217137336731]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05bd87a",
   "metadata": {},
   "source": [
    "### Training accuracy : 80.50%, Validation accuracy : 67.20% and Test accuracy : 80.65%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e533358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('E:\\Projects\\OCR-Sanskrit\\DeepCNN_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af642dde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
