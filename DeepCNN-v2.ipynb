{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b49fee2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yasha\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\yasha\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\yasha\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "358b52d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm  \n",
    "import tensorflow.keras\n",
    "import math\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02e4d9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"E:\\Projects\\OCR-Sanskrit\\DevanagariHandwrittenCharacterDataset\\Train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cbb99e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"E:\\Projects\\OCR-Sanskrit\\DevanagariHandwrittenCharacterDataset\\Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6efa70bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os.path\n",
    "\n",
    "filename = os.path.join('E:/Projects/OCR-Sanskrit/DevanagariHandwrittenCharacterDataset/Train/character_10_yna/10542.png')\n",
    "img = Image.open(filename)\n",
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "023c3d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=None,    \n",
    "    data_format='channels_first',\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "860c78e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 62560 images belonging to 46 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(32, 32),\n",
    "    color_mode = \"grayscale\",\n",
    "    batch_size=32,\n",
    "    shuffle = True,\n",
    "    classes = ['character_1_ka','character_2_kha','character_3_ga','character_4_gha','character_5_kna','character_6_cha',\n",
    "               'character_7_chha','character_8_ja','character_9_jha','character_10_yna','character_11_taamatar','character_12_thaa',\n",
    "               'character_13_daa', 'character_14_dhaa', 'character_15_adna', 'character_16_tabala', 'character_17_tha',\n",
    "               'character_18_da', 'character_19_dha', 'character_20_na', 'character_21_pa', 'character_22_pha','character_23_ba',\n",
    "               'character_24_bha','character_25_ma', 'character_26_yaw', 'character_27_ra', 'character_28_la', 'character_29_waw',\n",
    "               'character_30_motosaw', 'character_31_petchiryakha', 'character_32_patalosaw', 'character_33_ha', 'character_34_chhya', 'character_35_tra', \n",
    "               'character_36_gya','digit_0','digit_1','digit_2','digit_3','digit_4','digit_5','digit_6','digit_7','digit_8','digit_9'],\n",
    "    class_mode=\"sparse\",\n",
    "    subset='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c14d8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.preprocessing.image.DirectoryIterator at 0x15316613ca0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "975e87fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15640 images belonging to 46 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, # same directory as training data\n",
    "    target_size=(32, 32),\n",
    "    color_mode = \"grayscale\",\n",
    "    batch_size=32,\n",
    "    shuffle = True,\n",
    "    classes = ['character_1_ka','character_2_kha','character_3_ga','character_4_gha','character_5_kna','character_6_cha',\n",
    "               'character_7_chha','character_8_ja','character_9_jha','character_10_yna','character_11_taamatar','character_12_thaa',\n",
    "               'character_13_daa', 'character_14_dhaa', 'character_15_adna', 'character_16_tabala', 'character_17_tha',\n",
    "               'character_18_da', 'character_19_dha', 'character_20_na', 'character_21_pa', 'character_22_pha','character_23_ba',\n",
    "               'character_24_bha','character_25_ma', 'character_26_yaw', 'character_27_ra', 'character_28_la', 'character_29_waw',\n",
    "               'character_30_motosaw', 'character_31_petchiryakha', 'character_32_patalosaw', 'character_33_ha', 'character_34_chhya', 'character_35_tra', \n",
    "               'character_36_gya','digit_0','digit_1','digit_2','digit_3','digit_4','digit_5','digit_6','digit_7','digit_8','digit_9'],\n",
    "    class_mode=\"sparse\",\n",
    "    subset='validation') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e17376f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=None,    \n",
    "    data_format='channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4421bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13800 images belonging to 46 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(32, 32),\n",
    "    color_mode = \"grayscale\",\n",
    "    batch_size=32,\n",
    "    shuffle = True,\n",
    "    classes = ['character_1_ka','character_2_kha','character_3_ga','character_4_gha','character_5_kna','character_6_cha',\n",
    "               'character_7_chha','character_8_ja','character_9_jha','character_10_yna','character_11_taamatar','character_12_thaa',\n",
    "               'character_13_daa', 'character_14_dhaa', 'character_15_adna', 'character_16_tabala', 'character_17_tha',\n",
    "               'character_18_da', 'character_19_dha', 'character_20_na', 'character_21_pa', 'character_22_pha','character_23_ba',\n",
    "               'character_24_bha','character_25_ma', 'character_26_yaw', 'character_27_ra', 'character_28_la', 'character_29_waw',\n",
    "               'character_30_motosaw', 'character_31_petchiryakha', 'character_32_patalosaw', 'character_33_ha', 'character_34_chhya', 'character_35_tra', \n",
    "               'character_36_gya','digit_0','digit_1','digit_2','digit_3','digit_4','digit_5','digit_6','digit_7','digit_8','digit_9'],\n",
    "    class_mode=\"sparse\",\n",
    "    subset='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee5485b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2f59a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3151578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4635bb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1, 32, 32)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 7, 7)     1664        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 7, 7)     1664        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "merge1 (Concatenate)            (None, 128, 7, 7)    0           conv2d[0][0]                     \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 128, 4, 4)    0           merge1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 1, 1)    262272      max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 1, 1)    262272      max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "merge2 (Concatenate)            (None, 256, 1, 1)    0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 256, 1, 1)    0           merge2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 256, 1, 1)    590080      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 256, 1, 1)    590080      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 256, 1, 1)    590080      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 256, 1, 1)    590080      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 256, 1, 1)    590080      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 256, 1, 1)    590080      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "merge3 (Concatenate)            (None, 1536, 1, 1)   0           conv2d_4[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 1536, 1, 1)   0           merge3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1536, 1, 1)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1536)         0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 46)           70702       flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,139,054\n",
      "Trainable params: 4,139,054\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(1, 32, 32))\n",
    "\n",
    "fork11 = layers.Conv2D(64, 5, 5,  activation=\"relu\", padding='same')(inputs)\n",
    "fork12 = layers.Conv2D(64, 5, 5, activation=\"relu\", padding='same')(inputs)\n",
    "merge1 = layers.concatenate([fork11, fork12], axis=1, name='merge1')\n",
    "# concat_feat = concatenate([concat_feat, x], mode='concat', axis=concat_axis, name='concat_'+str(stage)+'_'+str(branch))\n",
    "maxpool1 = layers.MaxPool2D(strides=(2,2), padding='same')(merge1)\n",
    "\n",
    "fork21 = layers.Conv2D(128, 4, 4, activation=\"relu\", padding='same')(maxpool1)\n",
    "fork22 = layers.Conv2D(128, 4, 4, activation=\"relu\", padding='same')(maxpool1)\n",
    "merge2 = layers.concatenate([fork21, fork22, ], axis=1, name='merge2')\n",
    "maxpool2 = layers.MaxPool2D(strides=(2,2), padding='same')(merge2)\n",
    "\n",
    "fork31 = layers.Conv2D(256, 3, 3, activation=\"relu\", padding='same')(maxpool2)\n",
    "fork32 = layers.Conv2D(256, 3, 3, activation=\"relu\", padding='same')(maxpool2)\n",
    "fork33 = layers.Conv2D(256, 3, 3, activation=\"relu\", padding='same')(maxpool2)\n",
    "fork34 = layers.Conv2D(256, 3, 3, activation=\"relu\" , padding='same')(maxpool2)\n",
    "fork35 = layers.Conv2D(256, 3, 3, activation=\"relu\", padding='same')(maxpool2)\n",
    "fork36 = layers.Conv2D(256, 3, 3, activation=\"relu\", padding='same')(maxpool2)\n",
    "merge3 = layers.concatenate([fork31, fork32, fork33, fork34, fork35, fork36, ], axis=1, name='merge3')\n",
    "maxpool3 = layers.MaxPool2D(strides=(2,2), padding='same')(merge3)\n",
    "\n",
    "dropout = layers.Dropout(0.5)(maxpool3)\n",
    "\n",
    "flatten = layers.Flatten()(dropout)\n",
    "outputs = layers.Dense(46, activation=\"softmax\")(flatten)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b85072da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c99a45ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "100/100 [==============================] - 205s 2s/step - loss: 4.1844 - accuracy: 0.0859 - val_loss: 3.0171 - val_accuracy: 0.1703\n",
      "Epoch 2/15\n",
      "100/100 [==============================] - 139s 1s/step - loss: 2.7090 - accuracy: 0.2288 - val_loss: 2.4341 - val_accuracy: 0.2869\n",
      "Epoch 3/15\n",
      "100/100 [==============================] - 112s 1s/step - loss: 2.1532 - accuracy: 0.3606 - val_loss: 2.0947 - val_accuracy: 0.3809\n",
      "Epoch 4/15\n",
      "100/100 [==============================] - 99s 995ms/step - loss: 1.7769 - accuracy: 0.4663 - val_loss: 1.7735 - val_accuracy: 0.4778\n",
      "Epoch 5/15\n",
      "100/100 [==============================] - 91s 912ms/step - loss: 1.6545 - accuracy: 0.4956 - val_loss: 1.7697 - val_accuracy: 0.4759\n",
      "Epoch 6/15\n",
      "100/100 [==============================] - 82s 819ms/step - loss: 1.4840 - accuracy: 0.5609 - val_loss: 1.6896 - val_accuracy: 0.5122\n",
      "Epoch 7/15\n",
      "100/100 [==============================] - 86s 845ms/step - loss: 1.3009 - accuracy: 0.6000 - val_loss: 1.5996 - val_accuracy: 0.5309\n",
      "Epoch 8/15\n",
      "100/100 [==============================] - 67s 677ms/step - loss: 1.1805 - accuracy: 0.6316 - val_loss: 1.5691 - val_accuracy: 0.5387\n",
      "Epoch 9/15\n",
      "100/100 [==============================] - 83s 833ms/step - loss: 1.2047 - accuracy: 0.6353 - val_loss: 1.4597 - val_accuracy: 0.5597\n",
      "Epoch 10/15\n",
      "100/100 [==============================] - 67s 670ms/step - loss: 1.0761 - accuracy: 0.6675 - val_loss: 1.3519 - val_accuracy: 0.6062\n",
      "Epoch 11/15\n",
      "100/100 [==============================] - 118s 1s/step - loss: 1.0820 - accuracy: 0.6769 - val_loss: 1.3960 - val_accuracy: 0.5944\n",
      "Epoch 12/15\n",
      "100/100 [==============================] - 85s 859ms/step - loss: 1.0066 - accuracy: 0.6872 - val_loss: 1.4394 - val_accuracy: 0.5769\n",
      "Epoch 13/15\n",
      "100/100 [==============================] - 80s 793ms/step - loss: 0.9922 - accuracy: 0.7022 - val_loss: 1.2882 - val_accuracy: 0.6259\n",
      "Epoch 14/15\n",
      "100/100 [==============================] - 66s 665ms/step - loss: 0.9730 - accuracy: 0.7050 - val_loss: 1.4618 - val_accuracy: 0.5969\n",
      "Epoch 15/15\n",
      "100/100 [==============================] - 53s 532ms/step - loss: 0.9691 - accuracy: 0.7006 - val_loss: 1.3230 - val_accuracy: 0.6119\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    steps_per_epoch=100,\n",
    "                    validation_steps=100,\n",
    "                    epochs = 15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c5f0e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 85s 197ms/step - loss: 0.9074 - accuracy: 0.7233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9074335694313049, 0.7233333587646484]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05bd87a",
   "metadata": {},
   "source": [
    "### Training accuracy : 70.06%, Validation accuracy : 61.19% and Test accuracy : 72.33%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e533358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('E:\\Projects\\OCR-Sanskrit\\DeepCNN_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af642dde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
